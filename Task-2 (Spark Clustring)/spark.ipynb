{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conf': {'spark.jars.packages': 'org.mongodb.spark:mongo-spark-connector_2.11:2.3.2'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"conf\": {\"spark.jars.packages\": \"org.mongodb.spark:mongo-spark-connector_2.11:2.3.2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().set(\"spark.jars.packages\",\n",
    "\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    ).setMaster(\"local\").setAppName(\"SPARKhIRO\").setAll([\n",
    "    (\"spark.driver.memory\", \"3g\"),\n",
    "    (\"spark.executor.memory\", \"4g\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=SPARKhIRO, master=local) created by __init__ at /var/folders/bw/nlgnbf0x5gn4xvsfln7p7fsm0000gn/T/ipykernel_71737/1338432179.py:1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomaar/development/dataMining/data-mining-specialist-project/Task-1/part-B/spark.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomaar/development/dataMining/data-mining-specialist-project/Task-1/part-B/spark.ipynb#ch0000004?line=0'>1</a>\u001b[0m sc \u001b[39m=\u001b[39m SparkContext(conf \u001b[39m=\u001b[39;49m conf)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyspark/context.py:144\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=138'>139</a>\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=139'>140</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=140'>141</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=141'>142</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=143'>144</a>\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=144'>145</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=146'>147</a>\u001b[0m                   conf, jsc, profiler_cls)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyspark/context.py:350\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=346'>347</a>\u001b[0m     callsite \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_active_spark_context\u001b[39m.\u001b[39m_callsite\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=348'>349</a>\u001b[0m     \u001b[39m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=349'>350</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=350'>351</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot run multiple SparkContexts at once; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=351'>352</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexisting SparkContext(app=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, master=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=352'>353</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m created by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m at \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=353'>354</a>\u001b[0m         \u001b[39m%\u001b[39m (currentAppName, currentMaster,\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=354'>355</a>\u001b[0m             callsite\u001b[39m.\u001b[39mfunction, callsite\u001b[39m.\u001b[39mfile, callsite\u001b[39m.\u001b[39mlinenum))\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=355'>356</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/context.py?line=356'>357</a>\u001b[0m     SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=SPARKhIRO, master=local) created by __init__ at /var/folders/bw/nlgnbf0x5gn4xvsfln7p7fsm0000gn/T/ipykernel_71737/1338432179.py:1 "
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomaar/Library/Python/3.8/lib/python/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlC = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/12 00:37:01 WARN MongoInferSchema: Array Field 'storage_ids' contains conflicting types converting to StringType\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---------------------+--------+\n",
      "|               title|                body|rate|recommendation_status|is_buyer|\n",
      "+--------------------+--------------------+----+---------------------+--------+\n",
      "|             خوب بود|قدرت باتری مثل با...| 4.0|                 null|   false|\n",
      "|                null|             خوب است| 3.0|                 null|   false|\n",
      "|       گیم پس ۳ ماهه|عالی بود حتما پیش...| 4.0|          recommended|    true|\n",
      "|              گیم پس|بعد از یک روز اکا...| 3.0|              no_idea|    true|\n",
      "|             کاربردی|                عالی| 4.0|          recommended|    true|\n",
      "|       گیفکارت تقلبی|گیفت کارت تقلبی و...| 1.0|      not_recommended|    true|\n",
      "|         خوب و بصرفه|قیمت خوبی داره وب...| 3.0|          recommended|    true|\n",
      "|   حتما بخرید عالیه |  حتما بخرید عالیه\\n| 5.0|          recommended|    true|\n",
      "|                null|در فروش ویژه با ق...| 5.0|          recommended|    true|\n",
      "|                    |      قابلیت خوبش 9h| 4.0|          recommended|    true|\n",
      "|                    |       پیشنهاد میکنم| 5.0|          recommended|    true|\n",
      "|بنظرم مناسب گوشی ...|باسلام من دوتاسفا...| 4.0|          recommended|    true|\n",
      "|               کیفیت|من رنگ مشکی سفارش...| 2.0|              no_idea|    true|\n",
      "|     پایه نگهدارنده |قدرت ایستادگی خیل...| 0.0|      not_recommended|    true|\n",
      "|       پلاستیک مزخرف|به اندازه هزار تو...| 1.0|      not_recommended|    true|\n",
      "|             خوب بود|بسیار عالی بود من...| 5.0|                 null|   false|\n",
      "|                    |تا اونجایی که من ...|0.05|      not_recommended|    true|\n",
      "|عالی کارکرد بدون ...| عالی بود مشتریش شدم| 5.0|          recommended|    true|\n",
      "|              ناشناس|فروشگاه خوب با قی...| 5.0|          recommended|    true|\n",
      "|            پشتیبانی| پشتیبانی خیلی ضعیفه| 1.0|      not_recommended|    true|\n",
      "+--------------------+--------------------+----+---------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments = sqlC.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"spark.mongodb.input.uri\",\n",
    "                                                                      \"mongodb://root:root_password@localhost:28018/DK.comments?authSource=admin&readPreference=primary&appname=MongoDB%20Compass&ssl=false\").load()\n",
    "comments.createOrReplaceTempView(\"comments\")\n",
    "comments = sqlC.sql(\n",
    "    \"SELECT title,body,rate,recommendation_status,is_buyer  FROM comments\")\n",
    "comments.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
